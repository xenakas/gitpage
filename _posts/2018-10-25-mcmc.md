---
layout: post
title: "MCMC"
excerpt_separator: "<!--more-->"
categories:
  - Econometrics
tags:
  - approximation 
  - vocabulary 
---


<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


[Markov chain Monte Carlo](https://en.m.wikipedia.org/wiki/Markov_chain_Monte_Carlo) (MCMC) 
methods comprise a class of algorithms for sampling from a probability distribution. By constructing a Markov chain that 
has the desired distribution as its equilibrium distribution, one can obtain 
a sample of the desired distribution by observing the chain after a number of steps. 
The more steps there are, the more closely the distribution of the sample matches the actual 
desired distribution.

<!--more-->

Markov chain Monte Carlo methods are primarily used for calculating numerical 
approximations of multi-dimensional integrals, for example in Bayesian statistics

In Bayesian statistics, the recent development of Markov chain Monte Carlo methods has 
been a key step in making it possible to compute large hierarchical models that 
require integrations over hundreds or even thousands of unknown parameters.

In rare event sampling, they are also used for generating 
samples that gradually populate the rare failure region.



NUTS & HMC

Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior and sensitivity to correlated parameters that plague many MCMC methods by taking a series of steps informed by first-order gradient information.

However, HMC's performance is highly sensitive to two user-specified parameters: a step size and a desired number of steps L. In particular, if L is too small then the algorithm exhibits undesirable random walk behavior, while if L is too large the algorithm wastes computation. 

We introduce the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates the need to set a number of steps L. NUTS uses a recursive algorithm to build a set of likely candidate points that spans a wide swath of the target distribution, stopping automatically when it starts to double back and retrace its steps. Empirically, NUTS perform at least as efficiently as and sometimes more efficiently than a well tuned standard HMC method, without requiring user intervention or costly tuning runs. We also derive a method for adapting the step size parameter on the fly based on primal-dual averaging. NUTS can thus be used with no hand-tuning at all. NUTS is also suitable for applications such as BUGS-style automatic inference engines that require efficient "turnkey" sampling algorithms.

https://arxiv.org/pdf/1206.1901.pdf

https://arxiv.org/abs/1111.4246



#### Software:

R packages: 
- adaptMCMC 
- atmcmc
- BRugs  
- mcmc
- MCMCpack
- ramcmc
- rjags

[PyMC](https://docs.pymc.io)


[Stan](http://mc-stan.org) is a  platform for statistical modeling and high-performance 
statistical computation: full Bayesian statistical inference with MCMC sampling (NUTS, HMC), approximate
Bayesian inference with variational inference (ADVI), penalized maximum likelihood 
estimation with optimization (L-BFGS). 

- Additional R packages provide expression-based linear modeling, 
posterior visualization, and leave-one-out cross-validation. 

- [pystan](https://pystan.readthedocs.io/en/latest/getting_started.html) - Stan package for python


